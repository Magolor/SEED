{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we can create a new project and prepare the dataset in `.jsonl` format.\n",
    "We have already placed the required data files in advance. So now we can directly proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seed import *\n",
    "CreateProject(name=\"amazon_google\", workspace=\"../\")\n",
    "# Prepare data as `.jsonl` files if not exists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the project, a defult `config.json` is located under the projects' root folder, we can modify it to fit for our entity resolution task.\n",
    "The most important parameters are `name`, `task_desc`, `inputs`, `outputs`, `evaluation_metric` and `evaluation_path`, which should be defined by the user and should be application-specific.\n",
    "Here we use only the `Amazon-Google_demo.jsonl` dataset for ease of running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = LoadJson(\"config.json\")\n",
    "config = config | {\n",
    "    \"name\": \"entity_resolution\",\n",
    "    \"task_desc\": \"Given two products, determine whether they are identical product.\",\n",
    "    \"inputs\": [\n",
    "        {\n",
    "            \"name\": \"entity1\",\n",
    "            \"type\": \"dict\",\n",
    "            \"desc\": \"It contains three attributes: `title`, `manufacturer`, `price`. `title` and `manufacturer` are strings, `price` is float.\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"entity2\",\n",
    "            \"type\": \"dict\",\n",
    "            \"desc\": \"Same as entity1.\"\n",
    "        }\n",
    "    ],\n",
    "    \"outputs\": [\n",
    "        {\n",
    "            \"name\": \"is_same\",\n",
    "            \"type\": \"bool\",\n",
    "            \"desc\": \"0 if the two product are not identical, 1 of the two products are identical.\",\n",
    "            \"default\": 0\n",
    "        }\n",
    "    ],\n",
    "    \"evaluation_metric\": \"f1\",\n",
    "    \"evaluation_path\": \"./data/Amazon-Google_demo.jsonl\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, in many cases, if you have labelled training data, you can provide them with a little extra path settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config | {\n",
    "    \"examples_path\": \"./data/Amazon-Google_valid.jsonl\",\n",
    "    \"labelled_path\": \"./data/Amazon-Google_train.jsonl\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can directly compile the config file with a minimal component â€” the `llmqa` agent enabled by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveJson(config, \"config.json\")\n",
    "CompileProject(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After compilation, agent codes are generated under `./projects/amazon_google/agents/`, and you can directly test it for a single instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_entity_resolution_minimal_example(entity1, entity2):\n",
    "    from __init__ import entity_resolution\n",
    "    response = entity_resolution(entity1, entity2)\n",
    "    if response is None:\n",
    "        return \"Unknown (Probably an error has occurred)\"\n",
    "    return [\"The two entities are different!\", \"The two entities are the same!\"][response]\n",
    "\n",
    "print(test_entity_resolution_minimal_example(\n",
    "    entity1 = {\n",
    "        \"title\": \"Sony VCL-DH1774\",\n",
    "        \"manufacturer\": \"Sony\",\n",
    "        \"price\": 29.99\n",
    "    },\n",
    "    entity2 = {\n",
    "        \"title\": \"Sony VCL-DH1758\",\n",
    "        \"manufacturer\": \"Sony\",\n",
    "        \"price\": 20.99\n",
    "    }\n",
    "))\n",
    "print(test_entity_resolution_minimal_example(\n",
    "    entity1 = {\n",
    "        \"title\": \"Sony VCL-DH1774\",\n",
    "        \"manufacturer\": \"Sony\",\n",
    "        \"price\": 29.99\n",
    "    },\n",
    "    entity2 = {\n",
    "        \"title\": \"[DH 1774] Sony Variable Conversion Lens\",\n",
    "        \"manufacturer\": \"sony\",\n",
    "        \"price\": 28.99\n",
    "    }\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also batch evaluate all data in the `Amazon-Google.jsonl` by using `evaluation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import *\n",
    "evaluate_entity_resolution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After evaluation, a profile is generated under the root path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintJson(LoadJson(\"profile.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, as we have labelled data, we can finetune a model using the labelled data, which can be then used by the `cache` and `model` agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python train_model.py\n",
    "# However this could take quite some time, you can directly download the trained checkpoint here: \n",
    "# https://drive.google.com/file/d/16IORSgLIwtfFFqBojXt3BAEAPzRwgdNq/view?usp=sharing\n",
    "# The downloaded model checkpoint folder should be placed under `amazon_google/ckpts/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can setup the model path in the config and turn off online training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config | {\n",
    "    \"cache_frozen_ckpt\": \"./ckpts/amazon_google\",\n",
    "    \"model_initial_ckpt\": \"./ckpts/amazon_google\",\n",
    "    \"model_sync_off\": True,\n",
    "    \"activate_model\": True,\n",
    "    \"model_confidence_ratio\": 0.0,\n",
    "    \"model_confidence_default\": 0.0,\n",
    "}\n",
    "SaveJson(config, \"config.json\")\n",
    "CompileProject(\"./\")\n",
    "from evaluation import *\n",
    "evaluate_entity_resolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PrintJson(LoadJson(\"profile.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this demo example, the trained model is good enough (this is usually not the case for larger datasets).\n",
    "If you want to further optimize the hyperparameters, use `HyperparameterTuning` to search for the best configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HyperparameterTuning(\"./\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
